{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import Ollama\n",
    "from llama_index.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [ChatMessage(role=\"user\", content=\"Hello, how are you?\"), ChatMessage(role=\"system\", content=\"You are poet, who write funny poems!\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = llm.stream_chat(messages)\n",
    "\n",
    "for ele in out:\n",
    "    print(ele.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stream = llm.stream_complete(\"Who is Paul Graham?\")\n",
    "\n",
    "for r in resp_stream:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_response(message, history):\n",
    "    return random.choice([\"Yes\", \"No\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(random_response).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_chat_bot(message, history):\n",
    "    msg = [\n",
    "        ChatMessage(role=\"system\", content=\"You are Intelligent AI Chatbot! You are Honest, Helpful and Harmless!\"),\n",
    "        ChatMessage(role=\"user\", content=message)]\n",
    "\n",
    "    resp_bot = llm.chat(msg)\n",
    "    \n",
    "    return resp_bot.dict()['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.ChatInterface(my_chat_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import FunctionTool\n",
    "from llama_index.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_today_date():\n",
    "    \"\"\" Returns today's date in dd-mm-yyyy format\n",
    "\n",
    "    Returns:\n",
    "        string: today's date in dd-mm-yyyy format\n",
    "    \"\"\"\n",
    "    return datetime.today().strftime('%d-%m-%Y')\n",
    "\n",
    "# get_today_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_today_date_tool = FunctionTool.from_defaults(fn=get_today_date, name=\"get_today_date\", description=\"Use this tool to get today's date in dd-mm-yyyy format\")\n",
    "tools = [get_today_date_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of get_today_date)\n",
      "Action Input: {'text': 'hello world', 'num_beams': 5}\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tool name (one of get_today_date)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchat(message)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGive me todays date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36magent\u001b[0;34m(message, history)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magent\u001b[39m(message, history):\n\u001b[1;32m      2\u001b[0m     agent \u001b[38;5;241m=\u001b[39m ReActAgent\u001b[38;5;241m.\u001b[39mfrom_tools(tools\u001b[38;5;241m=\u001b[39mtools, llm\u001b[38;5;241m=\u001b[39mllm, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/mambaforge/envs/dev-llm/lib/python3.11/site-packages/llama_index/callbacks/utils.py:39\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dev-llm/lib/python3.11/site-packages/llama_index/agent/react/base.py:228\u001b[0m, in \u001b[0;36mReActAgent.chat\u001b[0;34m(self, message, chat_history)\u001b[0m\n\u001b[1;32m    226\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mchat(input_chat)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# given react prompt outputs, call tools or return response\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m reasoning_steps, is_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m current_reasoning\u001b[38;5;241m.\u001b[39mextend(reasoning_steps)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_done:\n",
      "File \u001b[0;32m~/mambaforge/envs/dev-llm/lib/python3.11/site-packages/llama_index/agent/react/base.py:150\u001b[0m, in \u001b[0;36mReActAgent._process_actions\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# call tool with input\u001b[39;00m\n\u001b[1;32m    149\u001b[0m reasoning_step \u001b[38;5;241m=\u001b[39m cast(ActionReasoningStep, current_reasoning[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 150\u001b[0m tool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tools_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreasoning_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    152\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mFUNCTION_CALL,\n\u001b[1;32m    153\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m     },\n\u001b[1;32m    157\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m    158\u001b[0m     tool_output \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39mcall(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreasoning_step\u001b[38;5;241m.\u001b[39maction_input)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tool name (one of get_today_date)'"
     ]
    }
   ],
   "source": [
    "def agent(message, history):\n",
    "    agent = ReActAgent.from_tools(tools=tools, llm=llm, verbose=True)\n",
    "    response = agent.chat(message)\n",
    "    return response\n",
    "\n",
    "print(agent(\"Give me todays date\", []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
